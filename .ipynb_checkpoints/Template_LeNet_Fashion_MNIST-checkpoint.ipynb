{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template_LeNet_Fashion_MNIST\n",
    "\n",
    "In this page, we will run LeNet model in AWS GPU remote server using Fashine MNIST data.\n",
    "\n",
    "We begin, as always, by importing modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "LeNet-5 is the latest convolutional network designed for handwritten and machine-printed character recognition.\n",
    "\n",
    "The LeNet-5 architecture consists of two sets of convolutional and average pooling layers, followed by a flattening convolutional layer, then two fully-connected layers, and finally, a softmax classifier.\n",
    "\n",
    "You can find more detailed information here: http://yann.lecun.com/exdb/lenet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cnn_inchannel,\n",
    "        cnn_hiddenchannel,\n",
    "        cnn_outchannel,\n",
    "        cnn_kernel,\n",
    "        full_hidden,\n",
    "        full_out,\n",
    "    ):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(cnn_inchannel, cnn_hiddenchannel, cnn_kernel)\n",
    "        self.conv2 = nn.Conv2d(cnn_hiddenchannel, cnn_outchannel, cnn_kernel)\n",
    "        self.fc1 = nn.Linear(4*4*cnn_outchannel, full_hidden)\n",
    "        self.fc2 = nn.Linear(full_hidden, full_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters of the model and build the model.\n",
    "We want to do forward propagation and backward propagation in GPU rather than CPU, so we move the mode to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_inchannel, cnn_hiddenchannel, cnn_outchannel, cnn_kernel = 1,20, 50, 5\n",
    "full_hidden, full_out = 400,10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet(cnn_inchannel, cnn_hiddenchannel, cnn_outchannel, cnn_kernel, full_hidden, full_out).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameters to run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs, lr = 10, 0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('~/datasets/F_MNIST/',\n",
    "                          train=True,\n",
    "                          download=True,\n",
    "                          transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('~/datasets/F_MNIST/',\n",
    "                          train=False,\n",
    "                          transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time we train and test the model, we need to move the data to GPU so that all the calculations are in GPU, which is much faster than running in CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
